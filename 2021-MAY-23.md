* As I continue to read Data Intensive Applications, I wonder why I was so late to pick up this book. Its awesome book - touching many topics at decent depth and explaining things very clearly.
* Re-watching Rich Hickey's [Persistent Data Structures and Managed References](https://www.infoq.com/presentations/Value-Identity-State-Rich-Hickey/) helped me think more about different data structures used in databases. Its amazing to see how a very old datastructure B-Trees is still very relevant. But looking at how Rich has implemented persistent immutable data structures, I keep wondering if something can be done to actually make these immutable datastuctures backed by disk. More reading and thinking needed here.
* I watched [EraDB's talk](https://www.youtube.com/watch?v=kfWHw4RemaM) on CMU DB group channel. Things I really found interesting are
  - Possible use of dimentionality to solve cardinality
  - Auto-indexing
  - Using ML to find out patterns in data and store and index them accordingly. This ML technique can also be used to see query patterns and identify possible indexes.
* Couple of days ago, my friend Abhijit [at hyphenos](https://hyphenos.io/authors/abhijit-gadgil/) shared [this article](https://zerodha.tech/blog/scaling-with-common-sense/) from Zerodha with me. Very nicely written article about general design guidelines. You can pick any one and it makes sense. When I was working at Xandr/Clypd, we used to follow many of these practices - many not exactly same but generally I felt that these thoughts aligned. I also felt good to know that there are many companies who are seeing success even with these straightforward, simple, easy to do design choices. Everyone doesn't have to think Google/Facebook scale from day 1. Even Google/Facebook didn't think about those things at their day 1. Scaling as and when required is natural way to build business. Doing it early because thats the industry buzzword, without knowing real requirements is big trap.
